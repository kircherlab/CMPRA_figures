{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso regression on motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd=\"/data/cephfs-2/unmirrored/groups/kircher/MPRA/CaptureCMPRA/\"\n",
    "bins = pl.read_csv(cd+\"results/MPRA_analysis/CMPRA5/labeled_data_promoteroa_OA.tsv\", separator='\\t').select(\n",
    "\tpl.col(\"promoter\"), #.str.head(-2),\n",
    "\tpl.col(\"OE\")#.str.head(-2)\n",
    "\t).unique()\n",
    "prom_motifs = pl.read_csv(cd+\"/results/motif_analysis/HOMER/upProm_find.filtered.tsv\", separator='\\t', has_header=False, skip_rows=1, \n",
    "\tnew_columns=[\"bin\", \"promoter\"]).with_columns(pl.col(\"bin\").str.replace(\":\", \"-\"), pl.col(\"promoter\").str.split(\".\").list.first())\n",
    "CRE_motifs = pl.read_csv(cd+\"results/motif_analysis/HOMER/upOE_find.filtered.tsv\", separator='\\t', has_header=False, skip_rows=1, \n",
    "\tnew_columns=[\"bin\", \"CRE\"]).with_columns(pl.col(\"bin\").str.replace(\":\", \"-\"), pl.col(\"CRE\").str.split(\".\").list.first())\n",
    "binary = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom_encoded = prom_motifs.to_dummies(\"promoter\").group_by(\"bin\").sum()\n",
    "CRE_encoded = CRE_motifs.to_dummies(\"CRE\").group_by(\"bin\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_input = bins.join(prom_encoded, left_on=\"promoter\", right_on=\"bin\").join(CRE_encoded, left_on=\"OE\", right_on=\"bin\").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom_motifs = pl.read_csv(cd+\"results/motif_analysis/HOMER/downProm_find.filtered.tsv\", separator='\\t', has_header=False, skip_rows=1, \n",
    "\tnew_columns=[\"bin\", \"promoter\"]).with_columns(pl.col(\"bin\").str.replace(\":\", \"-\"), pl.col(\"promoter\").str.split(\".\").list.first())\n",
    "CRE_motifs = pl.read_csv(cd+\"results/motif_analysis/HOMER/downOE_find.filtered.tsv\", separator='\\t', has_header=False, skip_rows=1, \n",
    "\tnew_columns=[\"bin\", \"CRE\"]).with_columns(pl.col(\"bin\").str.replace(\":\", \"-\"), pl.col(\"CRE\").str.split(\".\").list.first())\n",
    "prom_encoded = prom_motifs.to_dummies(\"promoter\").group_by(\"bin\").sum()\n",
    "CRE_encoded = CRE_motifs.to_dummies(\"CRE\").group_by(\"bin\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_input = bins.join(prom_encoded, left_on=\"promoter\", right_on=\"bin\").join(CRE_encoded, left_on=\"OE\", right_on=\"bin\").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promoter_ZFAT\n",
      "promoter_ZN37A\n",
      "promoter_ZN436\n",
      "promoter_ZN565\n",
      "promoter_ZNF500\n",
      "promoter_ZSC16\n",
      "CRE_ZFAT\n",
      "CRE_ZN490\n",
      "CRE_ZN565\n",
      "CRE_ZN578\n",
      "CRE_ZN627\n",
      "CRE_ZN736\n",
      "CRE_ZNF81\n"
     ]
    }
   ],
   "source": [
    "for col in down_input.columns:\n",
    "\tif col not in up_input.columns:\n",
    "\t\tprint(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promoter_OLIG1\n",
      "promoter_ONEC2\n",
      "promoter_ZN112\n",
      "promoter_ZN160\n",
      "promoter_ZN736\n",
      "CRE_MTF1\n",
      "CRE_POGK\n",
      "CRE_Z585B\n",
      "CRE_ZBED1\n",
      "CRE_ZFP41\n",
      "CRE_ZN37A\n",
      "CRE_ZN430\n",
      "CRE_ZNF92\n"
     ]
    }
   ],
   "source": [
    "for col in up_input.columns:\n",
    "\tif col not in down_input.columns:\n",
    "\t\tprint(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in up_input.columns:\n",
    "\tif col not in down_input.columns:\n",
    "\t\tdown_input = down_input.with_columns(pl.lit(0).cast(pl.Int64).alias(col))\n",
    "for col in down_input.columns:\n",
    "\tif col not in up_input.columns:\n",
    "\t\tup_input = up_input.with_columns(pl.lit(0).cast(pl.Int64).alias(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pl.concat([up_input.select(sorted(up_input.columns)), down_input.select(sorted(down_input.columns)).sample(up_input.height)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmpra = pl.read_csv(cd+\"/results/MPRA_analysis/CMPRA5/labeled_data_promoteroa_OA.tsv\", separator=\"\\t\").with_columns(\n",
    "\tpl.col(\"promoter\"),\n",
    "\tpl.col(\"OE\")).filter(pl.col(\"promoter\").is_not_null())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicates between up and down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = dummies.filter(pl.len().over([\"OE\", \"promoter\"]) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_z = cmpra.group_by([\"OE\", \"promoter\"]).agg(max_z = pl.col(\"z_score\").abs().max())\n",
    "if binary:\n",
    "\toutput = cmpra.with_columns(id = pl.col(\"promoter\") + pl.col(\"OE\")) \\\n",
    "\t\t.with_columns(output = pl.when(pl.col(\"id\").is_in(up_input.select(id=pl.col(\"promoter\") + pl.col(\"OE\")))).then(pl.lit(1))\\\n",
    "\t\t\t.when(pl.col(\"id\").is_in(down_input.select(id=pl.col(\"promoter\") + pl.col(\"OE\")))).then(pl.lit(-1))\\\n",
    "\t\t\t\t.otherwise(None)).filter(pl.col(\"output\").is_not_null()).select(\"id\", \"output\").unique()\n",
    "else:\n",
    "\toutput = cmpra.join(max_z, on=[\"OE\", \"promoter\"]).filter(pl.col(\"z_score\").abs() == pl.col(\"max_z\")) \\\n",
    "\t\t.with_columns(id=pl.col(\"promoter\") + pl.col(\"OE\")).select(\"id\", \"z_score\")\n",
    "dummies = dummies.with_columns(id=pl.col(\"promoter\") + pl.col(\"OE\"))#.select(pl.exclude(\"promoter\", \"OE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chrom = \"chr17|chr6\" # 15 of 6 of 17\n",
    "X_test = dummies.filter(pl.col(\"id\").str.contains(test_chrom))\n",
    "X_train = dummies.filter(pl.col(\"id\").str.contains(test_chrom).not_())\n",
    "y_test = output.join(X_test, on=\"id\", how=\"semi\")\n",
    "y_train = output.join(X_train, on=\"id\", how=\"semi\")\n",
    "X_test = X_test.join(y_test, on=[\"id\"], how=\"semi\")\n",
    "X_train = X_train.join(y_train, on=[\"id\"], how=\"semi\")\n",
    "X_train, X_test = X_train.sort(\"id\").select(pl.exclude(\"id\", \"OE\", \"promoter\")), X_test.sort(\"id\").select(pl.exclude(\"id\", \"OE\", \"promoter\"))\n",
    "y_train, y_test = y_train.sort(\"id\").select(pl.exclude(\"id\", \"OE\", \"promoter\")), y_test.sort(\"id\").select(pl.exclude(\"id\", \"OE\", \"promoter\"))\n",
    "X = pl.concat([X_train, X_test])\n",
    "y = pl.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(888, 914, 273, 247)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.filter(pl.col(\"output\") == 1).height, y_train.filter(pl.col(\"output\") == -1).height, y_test.filter(pl.col(\"output\") == 1).height, y_test.filter(pl.col(\"output\") == -1).height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1802, 520, 1802, 520)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.height, X_test.height, y_train.height, y_test.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/cephfs-1/work/groups/kircher/users/pkeukel_m/miniforge/envs/notebooks/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'l1_ratio': 0.5}\n",
      "Best ROC AUC score: 0.6134016599915273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1],  # Regularization strength\n",
    "    'l1_ratio': [0.1, 0.5, 0.9]  # ElasticNet mixing parameter\n",
    "}\n",
    "\n",
    "# Initialize the logistic regression model with ElasticNet penalty\n",
    "logistic = LogisticRegression(penalty='elasticnet', solver='saga', random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logistic,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',  # Use ROC AUC as the evaluation metric\n",
    "    cv=3,  # 5-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train.to_numpy().flatten())\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best ROC AUC score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Features:\n",
      "shape: (1_159, 2)\n",
      "┌─────────────────┬─────────────┐\n",
      "│ Feature         ┆ Coefficient │\n",
      "│ ---             ┆ ---         │\n",
      "│ str             ┆ f64         │\n",
      "╞═════════════════╪═════════════╡\n",
      "│ promoter_ZNF358 ┆ 0.137923    │\n",
      "│ CRE_ZN543       ┆ 0.129528    │\n",
      "│ CRE_HAND1       ┆ 0.124222    │\n",
      "│ promoter_ZN449  ┆ 0.124011    │\n",
      "│ CRE_ZBTB5       ┆ 0.121569    │\n",
      "│ …               ┆ …           │\n",
      "│ CRE_HMGA1       ┆ -0.116625   │\n",
      "│ promoter_CREM   ┆ -0.124852   │\n",
      "│ promoter_ZFX    ┆ -0.138854   │\n",
      "│ CRE_AHCTF1      ┆ -0.147801   │\n",
      "│ promoter_ZN460  ┆ -0.16865    │\n",
      "└─────────────────┴─────────────┘\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.63      0.63       247\n",
      "           1       0.67      0.67      0.67       273\n",
      "\n",
      "    accuracy                           0.65       520\n",
      "   macro avg       0.65      0.65      0.65       520\n",
      "weighted avg       0.65      0.65      0.65       520\n",
      "\n",
      "The train score for lasso model is 0.7502774694783574\n",
      "The test score for lasso model is 0.65\n",
      "Number of selected features: 233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.6489300173510699)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Fit Lasso Logistic Regression\n",
    "lasso = LogisticRegression(penalty='elasticnet', solver='saga', C=0.009, random_state=1, l1_ratio=0.1)\n",
    "lasso.fit(X_train, y_train.to_numpy().flatten())\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pl.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': lasso.coef_[0]\n",
    "}).sort('Coefficient',descending=True)\n",
    "\n",
    "print(\"Top Features:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = lasso.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "train_score_lr = lasso.score(X_train, y_train)\n",
    "test_score_lr = lasso.score(X_test, y_test)\n",
    "\n",
    "print(\"The train score for lasso model is {}\".format(train_score_lr))\n",
    "print(\"The test score for lasso model is {}\".format(test_score_lr))\n",
    "print(\"Number of selected features: {}\".format(np.sum(lasso.coef_ != 0)))\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected positive class motifs: 135\n",
      "Of which are enhancer motifs: 57\n",
      "Of which are promoter motifs: 78\n",
      "Number of motifs shared between promoter and enhancers: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of selected positive class motifs: {}\".format(np.sum(lasso.coef_ > 0)))\n",
    "print(\"Of which are enhancer motifs: {}\".format(feature_importance.filter(pl.col(\"Coefficient\") > 0).filter(pl.col(\"Feature\").str.contains(\"CRE_\")).height))\n",
    "print(\"Of which are promoter motifs: {}\".format(feature_importance.filter(pl.col(\"Coefficient\") > 0).filter(pl.col(\"Feature\").str.contains(\"promoter_\")).height))\n",
    "print(\"Number of motifs shared between promoter and enhancers: {}\".format(feature_importance.filter(pl.col(\"Coefficient\") > 0).select(pl.col(\"Feature\").str.strip_prefix(\"promoter_\").str.strip_prefix(\"CRE_\").unique_counts())\\\n",
    "\t.filter(pl.col(\"Feature\") > 1).height))\n",
    "feature_importance.filter(pl.col(\"Coefficient\") > 0).select(pl.col(\"Feature\").str.strip_prefix(\"promoter_\").str.strip_prefix(\"CRE_\").unique_counts())\\\n",
    "\t.filter(pl.col(\"Feature\") > 1).height / feature_importance.filter(pl.col(\"Coefficient\") > 0).height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected negative class motifs: 112\n",
      "Of which are enhancer motifs: 50\n",
      "Of which are promoter motifs: 62\n",
      "Number of motifs shared between promoter and enhancers: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05357142857142857"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of selected negative class motifs: {}\".format(np.sum(lasso.coef_ < 0)))\n",
    "print(\"Of which are enhancer motifs: {}\".format(feature_importance.filter(pl.col(\"Coefficient\") < 0).filter(pl.col(\"Feature\").str.contains(\"CRE_\")).height))\n",
    "print(\"Of which are promoter motifs: {}\".format(feature_importance.filter(pl.col(\"Coefficient\") < 0).filter(pl.col(\"Feature\").str.contains(\"promoter_\")).height))\n",
    "print(\"Number of motifs shared between promoter and enhancers: {}\".format(feature_importance.filter(pl.col(\"Coefficient\") < 0).select(pl.col(\"Feature\").str.strip_prefix(\"promoter_\").str.strip_prefix(\"CRE_\").unique_counts())\\\n",
    "\t.filter(pl.col(\"Feature\") > 1).height))\n",
    "feature_importance.filter(pl.col(\"Coefficient\") < 0).select(pl.col(\"Feature\").str.strip_prefix(\"promoter_\").str.strip_prefix(\"CRE_\").unique_counts())\\\n",
    "\t.filter(pl.col(\"Feature\") > 1).height / feature_importance.filter(pl.col(\"Coefficient\") < 0).height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not binary:\n",
    "\tlasso = Lasso(alpha=0.01)\n",
    "\tlasso.fit(X_train, y_train)\n",
    "\t# Using np.abs() to make coefficients positive.  \n",
    "\tlasso1_coef = np.abs(lasso.coef_)\n",
    "\ty_hat = lasso.predict(X_test)\n",
    "\n",
    "\ttrain_score_lr = lasso.score(X_train, y_train)\n",
    "\ttest_score_lr = lasso.score(X_test, y_test)\n",
    "\n",
    "\tprint(\"The train score for lasso model is {}\".format(train_score_lr))\n",
    "\tprint(\"The test score for lasso model is {}\".format(test_score_lr))\n",
    "\n",
    "\tplt.scatter(y_test.to_pandas(), y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_coefs = pl.concat([feature_importance.tail(50), feature_importance.head(50)])\n",
    "cre_coefs = top_coefs.filter(pl.col(\"Feature\").str.contains(\"CRE\"))\n",
    "prom_coefs = top_coefs.filter(pl.col(\"Feature\").str.contains(\"promoter\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 62)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cre_coefs.height, prom_coefs.height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motif combination regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_coefs = top_coefs.select(\"Feature\").to_numpy().flatten().tolist()\n",
    "all_combis = list(itertools.product(cre_coefs.select(\"Feature\").to_numpy().flatten().tolist(), prom_coefs.select(\"Feature\").to_numpy().flatten().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartesian_df = pl.DataFrame(all_combis, schema=[\"cre_motif\", \"prom_motif\"], orient=\"row\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feats = dummies.select(\"id\", cs.contains(top_coefs.select(\"Feature\").to_numpy().flatten().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "cres = selected_feats.select(cs.contains(\"CRE_\"))\n",
    "proms = selected_feats.select( cs.contains(\"promoter\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossed = dummies.select(\"id\")\n",
    "for cre_motif in cres.columns:\n",
    "\tfor prom_motif in proms.columns:\n",
    "\t\tnew_column = dummies.select(cre_motif, prom_motif).select(pl.all_horizontal(cre_motif, prom_motif).alias(cre_motif+\"-\"+prom_motif))\n",
    "\t\tcrossed = crossed.with_columns(new_column)\n",
    "\t\t#crossed = crossed.with_columns(new_column)\n",
    "#crossed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossed = crossed.with_columns(output = pl.when(pl.col(\"id\").is_in(up_input.select(id=pl.col(\"promoter\") + pl.col(\"OE\")))).then(pl.lit(1)).otherwise(pl.lit(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossed_train = crossed.filter(pl.col(\"id\").str.contains(test_chrom).not_())\n",
    "crossed_test = crossed.filter(pl.col(\"id\").str.contains(test_chrom))\n",
    "crossed_X_train = crossed_train.select(pl.exclude(\"id\", \"output\"))\n",
    "crossed_X_test = crossed_test.select(pl.exclude(\"id\", \"output\"))\n",
    "crossed_y_train = crossed_train.select(\"output\")\n",
    "crossed_y_test = crossed_test.select(\"output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(888, 914, 273, 247)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossed_train.filter(pl.col(\"output\") == 1).height, crossed_train.filter(pl.col(\"output\") == -1).height, crossed_test.filter(pl.col(\"output\") == 1).height, crossed_test.filter(pl.col(\"output\") == -1).height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/cephfs-1/work/groups/kircher/users/pkeukel_m/miniforge/envs/notebooks/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/cephfs-1/work/groups/kircher/users/pkeukel_m/miniforge/envs/notebooks/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/cephfs-1/work/groups/kircher/users/pkeukel_m/miniforge/envs/notebooks/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/cephfs-1/work/groups/kircher/users/pkeukel_m/miniforge/envs/notebooks/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/cephfs-1/work/groups/kircher/users/pkeukel_m/miniforge/envs/notebooks/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/cephfs-1/work/groups/kircher/users/pkeukel_m/miniforge/envs/notebooks/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/cephfs-1/work/groups/kircher/users/pkeukel_m/miniforge/envs/notebooks/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/cephfs-1/work/groups/kircher/users/pkeukel_m/miniforge/envs/notebooks/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/data/cephfs-1/work/groups/kircher/users/pkeukel_m/miniforge/envs/notebooks/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1, 'l1_ratio': 0.1}\n",
      "Best ROC AUC score: 0.7580095925795148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 0.5],  # Regularization strength\n",
    "    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]  # ElasticNet mixing parameter\n",
    "}\n",
    "\n",
    "# Initialize the logistic regression model with ElasticNet penalty\n",
    "logistic = LogisticRegression(penalty='elasticnet', solver='saga', random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logistic,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',  # Use ROC AUC as the evaluation metric\n",
    "    cv=3,  # 5-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(crossed_X_train, crossed_y_train.to_numpy().flatten())\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best ROC AUC score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Features:\n",
      "shape: (2_680, 2)\n",
      "┌─────────────────────────────┬─────────────┐\n",
      "│ Feature                     ┆ Coefficient │\n",
      "│ ---                         ┆ ---         │\n",
      "│ str                         ┆ f64         │\n",
      "╞═════════════════════════════╪═════════════╡\n",
      "│ CRE_ZN790-promoter_NFIC     ┆ 0.165926    │\n",
      "│ CRE_ZNF48-promoter_HAND1    ┆ 0.158294    │\n",
      "│ CRE_SRBP2-promoter_ZN667    ┆ 0.152057    │\n",
      "│ CRE_ZBTB5-promoter_ZN449    ┆ 0.143202    │\n",
      "│ CRE_ZN543-promoter_ZN790    ┆ 0.139312    │\n",
      "│ …                           ┆ …           │\n",
      "│ CRE_AHCTF1-promoter_ZN460   ┆ -0.180369   │\n",
      "│ CRE_TCF20-promoter_VEZF1    ┆ -0.189954   │\n",
      "│ CRE_AHCTF1-promoter_ZNF780B ┆ -0.203615   │\n",
      "│ CRE_PIT1-promoter_KLF16     ┆ -0.203903   │\n",
      "│ CRE_AHCTF1-promoter_ZBED5   ┆ -0.233034   │\n",
      "└─────────────────────────────┴─────────────┘\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.55      0.59       247\n",
      "           1       0.63      0.71      0.67       273\n",
      "\n",
      "    accuracy                           0.63       520\n",
      "   macro avg       0.63      0.63      0.63       520\n",
      "weighted avg       0.63      0.63      0.63       520\n",
      "\n",
      "The train score for lasso model is 0.6842397336293008\n",
      "The test score for lasso model is 0.6326923076923077\n",
      "Number of selected features: 50\n"
     ]
    }
   ],
   "source": [
    "# Fit Lasso Logistic Regression\n",
    "lasso = LogisticRegression(penalty='elasticnet', solver='saga', C=0.04, random_state=42, l1_ratio=0.8)\n",
    "lasso.fit(crossed_X_train, crossed_y_train.to_numpy().flatten())\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pl.DataFrame({\n",
    "    'Feature': crossed_X_train.columns,\n",
    "    'Coefficient': lasso.coef_[0]\n",
    "}).sort('Coefficient',descending=True)\n",
    "\n",
    "print(\"Top Features:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = lasso.predict(crossed_X_test)\n",
    "print(classification_report(crossed_y_test, y_pred))\n",
    "\n",
    "train_score_lr = lasso.score(crossed_X_train, crossed_y_train)\n",
    "test_score_lr = lasso.score(crossed_X_test, crossed_y_test)\n",
    "\n",
    "print(\"The train score for lasso model is {}\".format(train_score_lr))\n",
    "print(\"The test score for lasso model is {}\".format(test_score_lr))\n",
    "print(\"Number of selected features: {}\".format(np.sum(lasso.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Feature</th><th>Coefficient</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;CRE_ZN543-promoter_ZN790&quot;</td><td>0.411742</td></tr><tr><td>&quot;CRE_ZNF48-promoter_HAND1&quot;</td><td>0.394682</td></tr><tr><td>&quot;CRE_HAND1-promoter_NR2E1&quot;</td><td>0.393433</td></tr><tr><td>&quot;CRE_ZBTB5-promoter_ZN534&quot;</td><td>0.364801</td></tr><tr><td>&quot;CRE_SRBP2-promoter_ZN667&quot;</td><td>0.359048</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌──────────────────────────┬─────────────┐\n",
       "│ Feature                  ┆ Coefficient │\n",
       "│ ---                      ┆ ---         │\n",
       "│ str                      ┆ f64         │\n",
       "╞══════════════════════════╪═════════════╡\n",
       "│ CRE_ZN543-promoter_ZN790 ┆ 0.411742    │\n",
       "│ CRE_ZNF48-promoter_HAND1 ┆ 0.394682    │\n",
       "│ CRE_HAND1-promoter_NR2E1 ┆ 0.393433    │\n",
       "│ CRE_ZBTB5-promoter_ZN534 ┆ 0.364801    │\n",
       "│ CRE_SRBP2-promoter_ZN667 ┆ 0.359048    │\n",
       "└──────────────────────────┴─────────────┘"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.Config.set_fmt_str_lengths(200) \n",
    "feature_importance.sort('Coefficient', descending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Feature</th><th>Coefficient</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;CRE_TCF20.H13CORE.0.B.B-promoter_NANOG.H13CORE.1.P.B&quot;</td><td>-0.651732</td></tr><tr><td>&quot;CRE_SP7.H13CORE.0.P.B-promoter_MBD3.H13CORE.0.P.B&quot;</td><td>-0.570883</td></tr><tr><td>&quot;CRE_TCF20.H13CORE.0.B.B-promoter_ZFX.H13CORE.0.P.B&quot;</td><td>-0.556392</td></tr><tr><td>&quot;CRE_SP7.H13CORE.0.P.B-promoter_E2F1.H13CORE.0.P.B&quot;</td><td>-0.517438</td></tr><tr><td>&quot;CRE_MEF2D.H13CORE.1.M.C-promoter_E2F1.H13CORE.0.P.B&quot;</td><td>-0.498577</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌──────────────────────────────────────────────────────┬─────────────┐\n",
       "│ Feature                                              ┆ Coefficient │\n",
       "│ ---                                                  ┆ ---         │\n",
       "│ str                                                  ┆ f64         │\n",
       "╞══════════════════════════════════════════════════════╪═════════════╡\n",
       "│ CRE_TCF20.H13CORE.0.B.B-promoter_NANOG.H13CORE.1.P.B ┆ -0.651732   │\n",
       "│ CRE_SP7.H13CORE.0.P.B-promoter_MBD3.H13CORE.0.P.B    ┆ -0.570883   │\n",
       "│ CRE_TCF20.H13CORE.0.B.B-promoter_ZFX.H13CORE.0.P.B   ┆ -0.556392   │\n",
       "│ CRE_SP7.H13CORE.0.P.B-promoter_E2F1.H13CORE.0.P.B    ┆ -0.517438   │\n",
       "│ CRE_MEF2D.H13CORE.1.M.C-promoter_E2F1.H13CORE.0.P.B  ┆ -0.498577   │\n",
       "└──────────────────────────────────────────────────────┴─────────────┘"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.sort('Coefficient').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example x-points\n",
    "x_points = [-0.651732, -0.570883, -0.556392, -0.517438, -0.498577, 0.411742, 0.394682, 0.393433, 0.364801, 0.359048]\n",
    "\n",
    "# Create a gradient from red to green\n",
    "gradient = np.linspace(-1, 1, 500).reshape(1, -1)  # Gradient centered at 0\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 1))\n",
    "ax.imshow(gradient, aspect=\"auto\", cmap=\"RdYlGn\", extent=[-1, 1, -0.1, 0.1], vmin=-1, vmax=1)\n",
    "\n",
    "# Add black lines at x_points\n",
    "ax.vlines(x_points, ymin=-0.1, ymax=0.1, color='black', linewidth=1)\n",
    "sns.despine()\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_yticks([])  # Remove y-axis ticks\n",
    "ax.set_xlim(min(x_points) - 0.1, max(x_points) + 0.1)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
